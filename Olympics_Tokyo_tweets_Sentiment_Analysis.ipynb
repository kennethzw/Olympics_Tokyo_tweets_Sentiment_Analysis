{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af7583f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "import csv\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd394a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_data(fname):\n",
    "    txtdata = []\n",
    "    classes = []\n",
    "    topics  = []\n",
    "    with open(fname, 'r', encoding='UTF-', errors='ignore') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for row in reader:\n",
    "            if len(row)>1:\n",
    "                # get the text\n",
    "                txtdata.append(row[6])\n",
    "                # get the class (convert to integer)\n",
    "                if len(row)>1:\n",
    "                    classes.append(row[1])\n",
    "    \n",
    "    if (len(classes)>0) and (len(txtdata) != len(classes)):        \n",
    "        raise Exception(\"mismatched length!\"+ str(len(txtdata))+'***'+str(len(classes)))\n",
    "    \n",
    "    return (txtdata, classes)\n",
    "\n",
    "def read_text_data1(fname):\n",
    "    txtdata = []\n",
    "    classes = []\n",
    "    topics  = []\n",
    "    with open(fname, 'r', encoding='UTF-', errors='ignore') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for row in reader:\n",
    "            if len(row)>1:\n",
    "                # get the text\n",
    "                txtdata.append(row[0])\n",
    "                # get the class (convert to integer)\n",
    "                if len(row)>1:\n",
    "                    classes.append(row[1])\n",
    "    \n",
    "    if (len(classes)>0) and (len(txtdata) != len(classes)):        \n",
    "        raise Exception(\"mismatched length!\"+ str(len(txtdata))+'***'+str(len(classes)))\n",
    "    \n",
    "    return (txtdata, classes)\n",
    "\n",
    "\n",
    "def write_csv_kaggle_sub(fname, Y):\n",
    "    # fname = file name\n",
    "    # Y is a list/array with class entries\n",
    "    \n",
    "    # header\n",
    "    tmp = [['Id', 'Prediction']]\n",
    "    \n",
    "    # add ID numbers for each Y\n",
    "    for (i,y) in enumerate(Y):\n",
    "        tmp2 = [(i+1), y]\n",
    "        tmp.append(tmp2)\n",
    "        \n",
    "    # write CSV file\n",
    "    with open(fname, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c90523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n",
      "311439\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "# (if using Kaggle notebooks you need to include the directory path: /kaggle/input/cs5489-2020b-assignment-1/)\n",
    "# (traintxt, trainY, traintopic) = read_text_data(\"sanders_tweets_train.txt\")\n",
    "(traintxt, trainY) = read_text_data(\"train.csv\")\n",
    "(testtxt, _)                = read_text_data1(\"Olympics_Tokyo_tweets-copy1.csv\")\n",
    "print(len(traintxt))\n",
    "print(len(testtxt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa46a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT YOUR CODE HERE\n",
    "cntvect = feature_extraction.text.CountVectorizer(stop_words='english', max_features=90000)\n",
    "cntvect.fit(traintxt)\n",
    "# calculate the vectors for the training data\n",
    "trainX = cntvect.transform(traintxt)\n",
    "# calculate vectors for the test data\n",
    "testX = cntvect.transform(testtxt)\n",
    "# print the vocabulary\n",
    "# - (key,value) pairs correspond to (word,vector index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96b14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF representation\n",
    "# (For TF, pass use_idf=False)\n",
    "tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1', smooth_idf = False)\n",
    "# setup the TF-IDF representation, and transform the training set\n",
    "trainXtf = tf_trans.fit_transform(trainX)\n",
    "# transform the test set\n",
    "testXtf = tf_trans.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb451cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=26.366508987303583, gamma=2.6366508987303554)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "# setup the list of parameters to try\n",
    "paramgrid = {'C': logspace(-2,3,20),\n",
    "            'gamma': logspace(-4,3,20),\n",
    "            }\n",
    "# setup the cross-validation object\n",
    "# pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds\n",
    "svmcv = model_selection.GridSearchCV(svm.SVC(kernel='rbf'), paramgrid, cv=5, n_jobs=-1, verbose=True)\n",
    "# run cross-validation (train for each split)\n",
    "svmcv.fit(trainXtf, trainY);\n",
    "best_param = svmcv.best_params_\n",
    "clf = svm.SVC(kernel='rbf',C=best_param['C'],gamma=best_param['gamma'])\n",
    "clf.fit(trainXtf,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "028bf1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.2939441204071\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "predYnew = clf.predict(testXtf)\n",
    "write_csv_kaggle_sub(\"predictall.csv\", predYnew)\n",
    "\n",
    "end = time.time()\n",
    "print( end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9bb8c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 75.2939441204071\n"
     ]
    }
   ],
   "source": [
    "# shape(trainXtf)[0]\n",
    "# print('{} : {}'.format(n_cores, (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5704850",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d8aad3599d6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mstart1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "# from sklearn import svm\n",
    "\n",
    "# data_train = [[0,2,3],[1,2,3],[4,2,3]]\n",
    "# targets_train = [0,1,0]\n",
    "\n",
    "# clf = svm.SVC(kernel='rbf', degree=3, C=10, gamma=0.3, probability=True)\n",
    "# clf.fit(data_train, targets_train)\n",
    "\n",
    "# to_be_predicted = np.array([[1,3,4], [1,3,4], [1,3,5]])\n",
    "# clf.predict(to_be_predicted)\n",
    "#看看不同workers用多久\n",
    "for n_cores in range(1,17):\n",
    "# n_cores = 8\n",
    "\n",
    "    parallel = Parallel(n_jobs=n_cores)\n",
    "\n",
    "    start1 = time.time()\n",
    "\n",
    "\n",
    "    results = parallel(delayed(clf.predict)(testXtf[i].reshape(-1,12776))\n",
    "    for i in range(shape(testXtf)[0]))\n",
    "\n",
    "    predYnew = vstack(results).flatten()\n",
    "    write_csv_kaggle_sub(\"predictall_parallel.csv\", predYnew)\n",
    "\n",
    "    end1 = time.time()\n",
    "    print('{} : {}'.format(n_cores, (end1 - start1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0801f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分天预测\n",
    "from joblib import Parallel, delayed\n",
    "clf = svm.SVC(kernel = 'rbf',C=26.366508987303583, gamma=2.6366508987303554)\n",
    "clf.fit(trainXtf, trainY)\n",
    "timelist = ['2021-07-24','2021-07-25','2021-07-26','2021-07-27','2021-07-28','2021-07-29','2021-07-30','2021-07-31','2021-08-07','2021-08-08']\n",
    "\n",
    "for a in timelist:\n",
    "    (testtxt, _)                = read_text_data(a + \".csv\")\n",
    "    testX = cntvect.transform(testtxt)\n",
    "    testXtf = tf_trans.transform(testX)\n",
    "\n",
    "    n_cores = 7\n",
    "\n",
    "    parallel = Parallel(n_jobs=n_cores)\n",
    "\n",
    "    # start1 = time.time()\n",
    "\n",
    "\n",
    "    results = parallel(delayed(clf.predict)(testXtf[i].reshape(-1,12776))\n",
    "    for i in range(shape(testXtf)[0]))\n",
    "\n",
    "    predYnew = vstack(results).flatten()\n",
    "    write_csv_kaggle_sub(\"predictall_parallel\" + a + \".csv\", predYnew)\n",
    "\n",
    "# end1 = time.time()\n",
    "# print('{} : {}'.format(n_cores, (end1 - start1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc0300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
